{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c203d02-cf2b-4fdd-b646-0163247f6bfa",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Reproduce binary classification problems with CIPLS method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8aa28105-fa51-4f8b-aed5-bb8548d15dd3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900 100\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import gen_batches\n",
    "import numpy as np\n",
    "import h5py\n",
    "from Code.CIPLS import CIPLS\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "np.random.seed(12227)\n",
    "\n",
    "classifier = svm.LinearSVC(C=0.1, random_state=1227)\n",
    "method = 'CIPLS'\n",
    "memory_restricted = False\n",
    "batch_size = 128  # Required only if memory_restricted=True\n",
    "\n",
    "tmp = h5py.File('data/binary_data.h5', 'r')\n",
    "X_train, y_train = tmp['X_train'], tmp['y_train']\n",
    "X_test, y_test = tmp['X_test'], tmp['y_test']\n",
    "\n",
    "n_train, n_test = X_train.shape[0], X_test.shape[0]\n",
    "y_train, y_test = y_train[0:n_train], y_test[0:n_test]\n",
    "print(n_train, n_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8013d562-ab7e-4b86-8d05-d8fc477e30c9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method:[CIPLS] #Components[5] Mode:[Normal]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy [0.7800]\n"
     ]
    }
   ],
   "source": [
    "n_components = 5\n",
    "if memory_restricted:\n",
    "    print('Method:[{}] #Components[{}] Mode:[Memory Restricted]'.format(method, n_components))\n",
    "else:\n",
    "    print('Method:[{}] #Components[{}] Mode:[Normal]'.format(method, n_components))\n",
    "\n",
    "# If memory_sensitive=True the samples will be load in batch.\n",
    "# Otherwise, we load all samples into memory\n",
    "if memory_restricted == False:\n",
    "    X_train, y_train = X_train[0:n_train], y_train[0:n_train]\n",
    "    X_test, y_test = X_test[0:n_test], y_test[0:n_test]\n",
    "    batch_size = max(n_train, n_test)\n",
    "    tmp.close()\n",
    "    \n",
    "X_train_latent = np.zeros((n_train, n_components))\n",
    "X_test_latent = np.zeros((n_test, n_components))\n",
    "\n",
    "dm = CIPLS(n_components=n_components)\n",
    "\n",
    "for batch in gen_batches(n_train, batch_size):\n",
    "    dm.fit(X_train[batch], y_train[batch])\n",
    "\n",
    "for batch in gen_batches(n_train, batch_size):\n",
    "    X_train_latent[batch] = dm.transform(X_train[batch])\n",
    "\n",
    "for batch in gen_batches(n_test, batch_size):\n",
    "    X_test_latent[batch] = dm.transform(X_test[batch])\n",
    "        \n",
    "classifier.fit(X_train_latent, y_train[0:n_train])\n",
    "y_pred = classifier.predict(X_test_latent)\n",
    "\n",
    "acc = accuracy_score(y_test[0:n_test], y_pred)\n",
    "print('Accuracy [{:.4f}]'.format(acc, n_components))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dc6cfa1-4679-49dc-8129-e963470e3587",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method:[CIPLS] #Components[6] Mode:[Normal]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/video/data/tingan/GitRep/IPLSreview/Code/CIPLS.py:95: RuntimeWarning: overflow encountered in add\n",
      "  self.x_rotations[c]   += (u * l)\n",
      "/home/tingan/miniconda3/envs/pls/lib/python3.10/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m dm \u001b[38;5;241m=\u001b[39m CIPLS(n_components\u001b[38;5;241m=\u001b[39mn_components)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m gen_batches(n_train, batch_size):\n\u001b[0;32m---> 21\u001b[0m     \u001b[43mdm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m gen_batches(n_train, batch_size):\n\u001b[1;32m     24\u001b[0m     X_train_latent[batch] \u001b[38;5;241m=\u001b[39m dm\u001b[38;5;241m.\u001b[39mtransform(X_train[batch])\n",
      "File \u001b[0;32m/video/data/tingan/GitRep/IPLSreview/Code/CIPLS.py:98\u001b[0m, in \u001b[0;36mCIPLS.fit\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_loadings[:, c] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (u \u001b[38;5;241m*\u001b[39m t)\n\u001b[1;32m     97\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_loadings[:, c] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (l \u001b[38;5;241m*\u001b[39m t)\n\u001b[0;32m---> 98\u001b[0m             t \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(u, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_rotations\u001b[49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/video/data/tingan/GitRep/IPLSreview/Code/CIPLS.py:48\u001b[0m, in \u001b[0;36mCIPLS.normalize\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnormalize\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnewaxis\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mravel()\n",
      "File \u001b[0;32m~/miniconda3/envs/pls/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:1817\u001b[0m, in \u001b[0;36mnormalize\u001b[0;34m(X, norm, axis, copy, return_norm)\u001b[0m\n\u001b[1;32m   1814\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1815\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not a supported axis\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m axis)\n\u001b[0;32m-> 1817\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1818\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1819\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msparse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1820\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1821\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthe normalize function\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1822\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1823\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1824\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1825\u001b[0m     X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[0;32m~/miniconda3/envs/pls/lib/python3.10/site-packages/sklearn/utils/validation.py:921\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    915\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    916\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    917\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    918\u001b[0m         )\n\u001b[1;32m    920\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 921\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    929\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/miniconda3/envs/pls/lib/python3.10/site-packages/sklearn/utils/validation.py:161\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m     )\n\u001b[0;32m--> 161\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "n_components = 6\n",
    "if memory_restricted:\n",
    "    print('Method:[{}] #Components[{}] Mode:[Memory Restricted]'.format(method, n_components))\n",
    "else:\n",
    "    print('Method:[{}] #Components[{}] Mode:[Normal]'.format(method, n_components))\n",
    "\n",
    "# If memory_sensitive=True the samples will be load in batch.\n",
    "# Otherwise, we load all samples into memory\n",
    "if memory_restricted == False:\n",
    "    X_train, y_train = X_train[0:n_train], y_train[0:n_train]\n",
    "    X_test, y_test = X_test[0:n_test], y_test[0:n_test]\n",
    "    batch_size = max(n_train, n_test)\n",
    "    tmp.close()\n",
    "    \n",
    "X_train_latent = np.zeros((n_train, n_components))\n",
    "X_test_latent = np.zeros((n_test, n_components))\n",
    "\n",
    "dm = CIPLS(n_components=n_components)\n",
    "\n",
    "for batch in gen_batches(n_train, batch_size):\n",
    "    dm.fit(X_train[batch], y_train[batch])\n",
    "\n",
    "for batch in gen_batches(n_train, batch_size):\n",
    "    X_train_latent[batch] = dm.transform(X_train[batch])\n",
    "\n",
    "for batch in gen_batches(n_test, batch_size):\n",
    "    X_test_latent[batch] = dm.transform(X_test[batch])\n",
    "        \n",
    "classifier.fit(X_train_latent, y_train[0:n_train])\n",
    "y_pred = classifier.predict(X_test_latent)\n",
    "\n",
    "acc = accuracy_score(y_test[0:n_test], y_pred)\n",
    "print('Accuracy [{:.4f}]'.format(acc, n_components))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a10e799-6c1b-47a5-aef5-7fdb6c769018",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "python",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3 (ipykernel)",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": {
    "debugger": true
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "name": "Test_CIPLS.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
